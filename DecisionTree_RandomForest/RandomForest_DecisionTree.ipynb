{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('kyphosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kyphosis</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number</th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kyphosis  Age  Number  Start\n",
       "0   absent   71       3      5\n",
       "1   absent  158       3     14\n",
       "2  present  128       4      5\n",
       "3   absent    2       5      1\n",
       "4   absent    1       4     15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81 entries, 0 to 80\n",
      "Data columns (total 4 columns):\n",
      "Kyphosis    81 non-null object\n",
      "Age         81 non-null int64\n",
      "Number      81 non-null int64\n",
      "Start       81 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Kyphosis', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Kyphosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  4]\n",
      " [ 1  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.94      0.79      0.86        19\n",
      "     present       0.56      0.83      0.67         6\n",
      "\n",
      "    accuracy                           0.80        25\n",
      "   macro avg       0.75      0.81      0.76        25\n",
      "weighted avg       0.85      0.80      0.81        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_predicts = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  1]\n",
      " [ 4  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.82      0.95      0.88        19\n",
      "     present       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.80        25\n",
      "   macro avg       0.74      0.64      0.66        25\n",
      "weighted avg       0.78      0.80      0.77        25\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rfc_predicts))\n",
    "print(classification_report(y_test, rfc_predicts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent     64\n",
       "present    17\n",
       "Name: Kyphosis, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Kyphosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "** Use pandas to read loan_data.csv as a dataframe called loans.**\n",
    "\n",
    "loans = pd.read_csv('loan_data.csv')\n",
    "\n",
    "** Check out the info(), head(), and describe() methods on loans.**\n",
    "\n",
    "loans.info()\n",
    "\n",
    "loans.describe()\n",
    "\n",
    "loans.head()\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "Let's do some data visualization! We'll use seaborn and pandas built-in plotting capabilities, but feel free to use whatever library you want. Don't worry about the colors matching, just worry about getting the main idea of the plot.\n",
    "\n",
    "** Create a histogram of two FICO distributions on top of each other, one for each credit.policy outcome.**\n",
    "\n",
    "*Note: This is pretty tricky, feel free to reference the solutions. You'll probably need one line of code for each histogram, I also recommend just using pandas built in .hist()*\n",
    "\n",
    "credits_1 = loans[loans['credit.policy'] == 1]['fico']\n",
    "credits_0 = loans[loans['credit.policy'] == 0]['fico']\n",
    "plt.figure(figsize=(10,6))\n",
    "credits_0.hist(bins=30, label='Credit=0',color = 'red', alpha=0.5)\n",
    "credits_1.hist(bins=30, label='Credit=1',color = 'blue', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('FICO')\n",
    "\n",
    "** Create a similar figure, except this time select by the not.fully.paid column.**\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "loans[loans['not.fully.paid'] == 1]['fico'].hist(bins=30,color='blue',label='Yes', alpha=0.5)\n",
    "loans[loans['not.fully.paid'] == 0]['fico'].hist(bins=30,color='red',label='No', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.xlabel('FICO')\n",
    "\n",
    "** Create a countplot using seaborn showing the counts of loans by purpose, with the color hue defined by not.fully.paid. **\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(x='purpose',data=loans, hue='not.fully.paid')\n",
    "\n",
    "** Let's see the trend between FICO score and interest rate. Recreate the following jointplot.**\n",
    "\n",
    "sns.jointplot(x='fico',y='int.rate',data=loans)\n",
    "\n",
    "** Create the following lmplots to see if the trend differed between not.fully.paid and credit.policy. Check the documentation for lmplot() if you can't figure out how to separate it into columns.**\n",
    "\n",
    "sns.lmplot(x='fico',y='int.rate',data=loans,hue='credit.policy',col='not.fully.paid')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Setting up the Data\n",
    "\n",
    "Let's get ready to set up our data for our Random Forest Classification Model!\n",
    "\n",
    "**Check loans.info() again.**\n",
    "\n",
    "loans.info()\n",
    "\n",
    "## Categorical Features\n",
    "\n",
    "Notice that the **purpose** column as categorical\n",
    "\n",
    "That means we need to transform them using dummy variables so sklearn will be able to understand them. Let's do this in one clean step using pd.get_dummies.\n",
    "\n",
    "Let's show you a way of dealing with these columns that can be expanded to multiple categorical features if necessary.\n",
    "\n",
    "**Create a list of 1 element containing the string 'purpose'. Call this list cat_feats.**\n",
    "\n",
    "loans['cat_feats'] = loans['purpose']\n",
    "\n",
    "**Now use pd.get_dummies(loans,columns=cat_feats,drop_first=True) to create a fixed larger dataframe that has new feature columns with dummy variables. Set this dataframe as final_data.**\n",
    "\n",
    "final_data = pd.get_dummies(data = loans, columns=['cat_feats'], drop_first=True)\n",
    "\n",
    "final_data.drop('purpose', axis=1, inplace=True)\n",
    "\n",
    "## Train Test Split\n",
    "\n",
    "Now its time to split our data into a training set and a testing set!\n",
    "\n",
    "** Use sklearn to split your data into a training set and a testing set as we've done in the past.**\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_data.drop('not.fully.paid', axis=1)\n",
    "y = final_data['not.fully.paid']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "## Training a Decision Tree Model\n",
    "\n",
    "Let's start by training a single decision tree first!\n",
    "\n",
    "** Import DecisionTreeClassifier**\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "**Create an instance of DecisionTreeClassifier() called dtree and fit it to the training data.**\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "## Predictions and Evaluation of Decision Tree\n",
    "**Create predictions from the test set and create a classification report and a confusion matrix.**\n",
    "\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "\n",
    "## Training the Random Forest model\n",
    "\n",
    "Now its time to train our model!\n",
    "\n",
    "**Create an instance of the RandomForestClassifier class and fit it to our training data from the previous step.**\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "## Predictions and Evaluation\n",
    "\n",
    "Let's predict off the y_test values and evaluate our model.\n",
    "\n",
    "** Predict the class of not.fully.paid for the X_test data.**\n",
    "\n",
    "predictions = rfc.predict(X_test)\n",
    "\n",
    "**Now create a classification report from the results. Do you get anything strange or some sort of warning?**\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(y_test,predictions))\n",
    "\n",
    "**Show the Confusion Matrix for the predictions.**\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
